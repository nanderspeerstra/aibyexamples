{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Reward matrix R, learning matrix Q and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize \n",
    "R = np.matrix([ [0,0,0,0,1,0],\n",
    "                [0,0,0,1,0,1],\n",
    "                [0,0,100,1,0,0],\n",
    "                [0,1,1,0,1,0],\n",
    "                [1,0,0,1,0,0],\n",
    "                [0,1,0,0,0,0] ])\n",
    "Q = np.matrix( np.zeros([6,6]) )\n",
    "\n",
    "gamma = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_s_state = 1\n",
    "\n",
    "def possible_actions(state):\n",
    "    current_state_row = R[state,]\n",
    "    \n",
    "    #print(current_state_row)\n",
    "    #[[0 0 0 1 0 1]]\n",
    "    \n",
    "    possible_act = np.where(current_state_row > 0) [1]\n",
    "    return possible_act\n",
    "\n",
    "PossibleAction = possible_actions(agent_s_state)\n",
    "#print(PossibleAction)\n",
    "#[3 5]\n",
    "\n",
    "def ActionChoice(available_actions_range):\n",
    "    next_action = int(np.random.choice(PossibleAction, 1))\n",
    "    return next_action\n",
    "\n",
    "action = ActionChoice(PossibleAction)\n",
    "#print(action)\n",
    "#3  (or '5' of course => one of the 2 possible actions in state 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(current_state, action, gamma):\n",
    "    Max_State = np.where(Q[action,] == np.max(Q[action,]))[1]\n",
    "    #print(Max_State)\n",
    "    #[0 1 2 3 4 5]   => can only choose between 6 states\n",
    "    \n",
    "    if (Max_State.shape[0] > 1):\n",
    "        Max_State = int(np.random.choice(Max_State, size = 1))\n",
    "    else:\n",
    "        Max_State = int(Max_State)\n",
    "    MaxValue = Q[action, Max_State]\n",
    "    #print(MaxValue)\n",
    "    #0.0    => is first time always 0, because Q is filled with zeros\n",
    "    \n",
    "    Q[current_state, action] = R[current_state, action] + gamma * MaxValue\n",
    "    #print(Q[current_state,])\n",
    "    #[[0. 0. 0. 1. 0. 0.]]\n",
    "\n",
    "reward(agent_s_state, action, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50000):\n",
    "    # Start at a random location\n",
    "    current_state = np.random.randint(0, int(Q.shape[0]))\n",
    "    \n",
    "    # Get the possible actions\n",
    "    PossibleAction = possible_actions(current_state)\n",
    "    \n",
    "    # Choose an action\n",
    "    action = ActionChoice(PossibleAction)\n",
    "    \n",
    "    # Reward\n",
    "    reward(current_state, action, gamma)\n",
    "    \n",
    "    # Print Q after the first 2 actions and rewards (example)\n",
    "    #print(\"Q:\")\n",
    "    #print(Q)\n",
    "    #if i == 1: break\n",
    "    \"\"\"[[0.  0.  0.  0.  0.  0. ]\n",
    "        [0.  0.  0.  1.  0.  1. ]\n",
    "        [0.  0.  0.  1.  0.  0. ]\n",
    "        [0.  1.8 0.  0.  0.  0. ]\n",
    "        [1.  0.  0.  0.  0.  0. ]\n",
    "        [0.  0.  0.  0.  0.  0. ]]\n",
    "        \n",
    "        [[0.   0.   0.   0.   0.   0.  ]\n",
    "         [0.   0.   0.   1.   0.   1.  ]\n",
    "         [0.   0.   0.   2.44 0.   0.  ]\n",
    "         [0.   1.8  0.   0.   0.   0.  ]\n",
    "         [1.   0.   0.   0.   0.   0.  ]\n",
    "         [0.   0.   0.   0.   0.   0.  ]]\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Q:\n",
      "[[  0.      0.      0.      0.    258.44    0.   ]\n",
      " [  0.      0.      0.    321.8     0.    207.752]\n",
      " [  0.      0.    500.    321.8     0.      0.   ]\n",
      " [  0.    258.44  401.      0.    258.44    0.   ]\n",
      " [207.752   0.      0.    321.8     0.      0.   ]\n",
      " [  0.    258.44    0.      0.      0.      0.   ]]\n",
      "\n",
      "Normed Q:\n",
      "[[  0.       0.       0.       0.      51.688    0.    ]\n",
      " [  0.       0.       0.      64.36     0.      41.5504]\n",
      " [  0.       0.     100.      64.36     0.       0.    ]\n",
      " [  0.      51.688   80.2      0.      51.688    0.    ]\n",
      " [ 41.5504   0.       0.      64.36     0.       0.    ]\n",
      " [  0.      51.688    0.       0.       0.       0.    ]]\n",
      "\n",
      "Binary Q (value 100 is also 1):\n",
      "[[0 0 0 0 1 0]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 1 1 0 0]\n",
      " [0 1 1 0 1 0]\n",
      " [1 0 0 1 0 0]\n",
      " [0 1 0 0 0 0]]\n",
      "\n",
      "What it should look like (R):\n",
      "[[  0   0   0   0   1   0]\n",
      " [  0   0   0   1   0   1]\n",
      " [  0   0 100   1   0   0]\n",
      " [  0   1   1   0   1   0]\n",
      " [  1   0   0   1   0   0]\n",
      " [  0   1   0   0   0   0]]\n",
      "\n",
      "Binary Q and Binary R are equal: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Latest Q:\")\n",
    "print(Q)\n",
    "print()\n",
    "\n",
    "print(\"Normed Q:\")\n",
    "print(Q/np.max(Q)*100)\n",
    "print()\n",
    "\n",
    "print(\"Binary Q (value 100 is also 1):\")\n",
    "print(np.where(Q > 0, 1, 0))\n",
    "print()\n",
    "\n",
    "print(\"What it should look like (R):\")\n",
    "print(R)\n",
    "print()\n",
    "\n",
    "print(\"Binary Q and Binary R are equal: {}\".format(np.array_equal(np.where(Q > 0, 1, 0), np.where(R > 0, 1, 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, the binary Q and R are identical. Training finished successfully!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
